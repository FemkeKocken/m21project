**Introduction**

In 2022 OpenAI launched ChatGPT, a Large Language Model (LLM) running on GPT3. Unique about this software was that it can interpret language, therefore doesn’t need keywords, has an enormous data bank to reference and can answer in coherent and informative texts (source: yt video aiwar). ChatGPT has become the fastest-growing app to date. Having surpassed the 100 million mark in January 2023, 14 months after its release (OpenAI source). The model is mostly used as a chatbot, where people ask questions, but it can also write texts, songs, poems, articles and reports that are, for the most part, indistinguishable from human-written text. Models for text generation and image generation have already won from humans in small art contests. (SOURCE). Major stakeholders in the development of LLM and Generative Artificial intelligence (GAI), are OpenAI, Google Deep Mind, Microsoft and Google. In 2023 Microsoft alone invested 10 billion USD in OpenAI alone ( https://www.nytimes.com/2023/01/23/business/microsoft-chatgpt-artificial-intelligence.html#:~:text=The%20tech%20giant%20aims%20to,with%20its%20partnership%20with%20OpenAI ). Proving to be that GAI is an incredibly powerful tool, developing at an enormous speed. It is yet to be determined what role it will play in everyday life, but there are already some first issues arising regarding integrity, impersonation and the conscience of these, and the use of, these models. 

**Theoretical framework** 
**Explain GAI**

GAI is a collective term of AI that is able to generate content output. This output can be in the form of text, video, images and audio. The content itself is generated, or made, by the system and did not exist beforehand. Currently there are multiple popular programs, each specialized in their own output. For example OpenAI DALL-e can generate images based on text input, GPT3 can output coherent text such as songs and poems, Faceapp can edit people into media, also known as deep faking, human voice can be mimicked as well as generated such as vocaloids like Hatsune Miku.utilizing VOCALOID6 ( https://www.vocaloid.com/en/#:~:text=VOCALOID6%20is%20an%20AI%2Dbased,to%20express%20your%20vocal%20ideas.  ).  

**(should explaining LLMs be it’s own paragraph?)**

Diving a bit deeper into GAI with text output, you see a field of competing LLMs, the most popular, likes ChatGPT, Google BARD and Dalton use Natural Language Processing. Meaning that they are able to interpret human input, not relying on keywords. 

**How does it technically classify** 
From a technical viewpoint most Artificial Intelligence gain their intelligence from machine learning, way to let programs classify data.  This can be done by supervising the data set, meaning that data is labeled in predetermined classes and the assignment into said class will be done by the program. In unsupervised learning the program will have to label the data itself, and will aim to group data together in clusters. Within unsupervised learning and most relevant for this project is Deep learning, with the aim to mimick human learning by programs, by designing Neural Networks. These neural networks are part of how NLP powers the LLM that drive programs such as GPT3 and ChatGPT. 
Sources: https://www.youtube.com/watch?v=CMrHM8a3hqw&ab_channel=Simplilearn
https://www.youtube.com/watch?v=k2P_pHQDlp0&list=WL&index=8&ab_channel=KrishNaik 

**How do Neural Networks work**

Neural networks exist of layers that will move input data, though the channels of the layer towards the output layer and the classification of the data. This input is broken down and fed as a value input to the first neuron layer. Each individual neuron is connect to the next by the cannels and are multiplied by a numerical weight of importance. This sum is then transported to the next hidden layer where the bias will be determined. This activation functions helps to propagate the information forward through the network until the system will eventually classify the information based on the probability. What this means for text is that it is possible to not only to classify letters, and predict what letter should come next (think of auto-fill or auto-correct functions), but by utilizing grammar techniques it can also form sentences and stories and giving it a data bank of information to reference it is able to formulate informative sentences as well. 
https://www.youtube.com/watch?v=bfmFfD2RIcg&ab_channel=Simplilearn 

**Methodology**

One more pressing but currently unexplored aspect of GAI is how to relate towards this new technology. Therefore this research will explore multiple design fictions centred on the relationship people have towards GAI with the aim to showcase extreme cases and spark discussion.

[A bit about design fiction and speculative research] 

In order to explore interesting relationships towards GAI, I utilized the Analogies and Metaphors tool, which focusses on understanding the current landschape and relationships people have towards similar technology and placing this in a new context. After defining some relationships, I saw four cluster emerge based on the trust in GAI and how inclusive GAI would be for humans. 

I found that these four clusters, where all suitable for further defining, which I did by making a collage and  a soundscape to define four worlds in which GAI had successfully been implemented and in which people had developed one of the four relationships toward the GAI; GAI as a part of your identity, GAI as part of reality, GAI as a caregiver, and GAI as a authoritarian force. Taking the time set for this project, as well as coding with GPT-4 or programs similar to that, it was decided to place more importance on exploring all four relationships broadly through non-working prototypes, and to go in-depth on the most interesting relationship and create a working prototype in my upcoming Final Master Project. 

sources:
Expertise and the use of visual analogy: implications for design education
A guide to metaphors in creative design
A guide to metaphorical Design and the concrete
Product expresion Bridging the gap between the symbolic and the concrete
Page 161 design guide

**GAI as a part of your identity**
This relationship is centered in a world where GAI has been implemented to the extent that it has now become a fundamental part of how we can identify ourselves. Humanity has become the sum of its physical and, more importantly, digital parts. This is based on technologies that become part of the human users; these include spelling checkers as well as devices that help in maintaining [correct term needed] bloodsugar levels in diabetis patients. These technologies post for philosophical questions surrounding trans-humanism, where it is interesting to explore the blurred lines between the tool or technology and the user. 

In a first design exploration I developed a concept around GAI as a tool that has replaced all other tool; The Final Product. It would take the shape of a futuristic cap that would let the participant listen to the audio of the set up of this product. While I enjoyed the idea of exploring the border of where the human end and the technology begins. This concept was set in a future too distant to come across as believable. 

Something much more relatable is the increasing difficulty to log in, to proof right of access into your digital accounts. There are many form of digital identification with different levels of intimacy. This includes, passwords, pincodes, biometics and voice authentication. This led me to explore a digital prototype in which the aim was log-in through increasingly more methods of authentication, with one final test, proofing that you are not a robot by ticking the box, and failing. In this proposed relationship humanity has merged and where digital identity has become recognized as one’s proof of existence. 

[Look and feel of log-in]

**GAI as part of reality**

**GAI as a caregiver** 
**GAI as a authoritarian force**


